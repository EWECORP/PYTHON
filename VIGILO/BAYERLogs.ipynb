{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYER - VIGILOO --> Control de Interfaces y Consistencia de DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "def obtener_enlaces(url):\n",
    "    # Realizar la petición HTTP a la página web\n",
    "    respuesta = requests.get(url)\n",
    "    # Si la petición fue exitosa, procesar el contenido\n",
    "    if respuesta.status_code == 200:\n",
    "        soup = BeautifulSoup(respuesta.content, 'html.parser')\n",
    "        # Extraer todos los elementos <a> de la página\n",
    "        enlaces = soup.find_all('a', href=True)\n",
    "        # Crear una lista para almacenar los datos\n",
    "        datos = []\n",
    "        # Recorrer cada enlace y almacenar la información necesaria\n",
    "        for enlace in enlaces:\n",
    "            # Extraer el href del enlace\n",
    "            href = enlace['href']\n",
    "            # Extraer el texto del enlace, que es el nombre del archivo\n",
    "            texto = enlace.text\n",
    "            # Intentar extraer las observaciones que están en el contenido antes del enlace\n",
    "            # Esto asume que el texto de observaciones está justo antes del enlace\n",
    "            observaciones = enlace.previous_sibling\n",
    "            if observaciones:\n",
    "                observaciones = observaciones.strip()  #Remueve los espacios al principio y al final de la línea\n",
    "                # Dividir las observaciones en partes\n",
    "                partes = observaciones.split(\"   \")\n",
    "                #print(partes)\n",
    "                # Extraer la fecha y la hora (primeras dos partes)\n",
    "                fecha_hora = ' '.join(partes[:1])\n",
    "                #print(fecha_hora)\n",
    "                # Extraer el tamaño (última parte)\n",
    "                tamaño = partes[-1]\n",
    "                #print(tamaño)\n",
    "            else:\n",
    "                fecha_hora = \"No disponible\"\n",
    "                tamaño = \"No disponible\"\n",
    "            # Añadir a la lista como una tupla\n",
    "            datos.append((texto, \"http://rtv-b2b-api-logs.vigiloo.net\" + href, fecha_hora, tamaño))    # datos.append((texto, url + href, fecha_hora, tamaño))\n",
    "        # Convertir la lista en un DataFrame\n",
    "        df = pd.DataFrame(datos, columns=['NombreArchivo', 'URL', 'FechaHora', 'Tamaño'])\n",
    "        df.drop(0,axis=0)\n",
    "        # Convertir la columna 'FechaHora' a tipo datetime\n",
    "        df['FechaHora'] = pd.to_datetime(df['FechaHora'], dayfirst=False, format='%m/%d/%Y %I:%M %p',errors='coerce') \n",
    "        # Convertir la columna 'Tamaño' a tipo numérico\n",
    "        df['Tamaño'] = pd.to_numeric(df['Tamaño'], errors='coerce')\n",
    "        df['Embarque'] = df['NombreArchivo'].str.extract(r'-(\\d+)\\.log')\n",
    "        df.drop(0,axis=0, inplace=True)  # Borro la Primera línea que apunta al directorio padre        \n",
    "        return df\n",
    "    else:\n",
    "        return \"Error al acceder a la página\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Dataframe con el TOTAL de los archivos existentes de archivos de Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página de donde se desean extraer los enlaces\n",
    "url = \"http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/\"\n",
    "archivos_df = obtener_enlaces(url)\n",
    "if isinstance(archivos_df, pd.DataFrame):\n",
    "   print(archivos_df.head(1))\n",
    "else:\n",
    "   print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRAR Archivos_df y generar subset en archivo SALIDA\n",
    "# Inicio Nueva Nomenclatura de Archivos 01/18/2024\n",
    "\n",
    "fecha_inicio = datetime.datetime(year=2025,month=1,day=1)\n",
    "\n",
    "entrada = archivos_df[(archivos_df['FechaHora'] >=fecha_inicio)]\n",
    "#salida.dropna()\n",
    "# print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrada.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRADO y ORDENADO del dataframe para procesar secuencialmente\n",
    "\n",
    "graficar = entrada.sort_values(by=['Embarque', 'FechaHora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuento de la Cantidad de Archvios por Minuto\n",
    "agruparD = graficar['FechaHora'].dt.floor('D').value_counts()\n",
    "\n",
    "#agruparD = graficar['FechaHora'].dt.floor('min').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agruparD[\"Fecha\"] = [date.strftime('%Y-%m-%d') for date in  agruparD.index]\n",
    "agruparD['Fecha'] = pd.to_datetime(agruparD.index, format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agruparD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graficar.head())\n",
    "print(graficar.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graficar.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agruparD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Verificar si la columna FechaHora es válida\n",
    "if 'FechaHora' not in graficar.columns:\n",
    "    raise ValueError(\"La columna 'FechaHora' no existe en el DataFrame.\")\n",
    "\n",
    "# Convertir a datetime si es necesario\n",
    "if not pd.api.types.is_datetime64_any_dtype(graficar['FechaHora']):\n",
    "    graficar['FechaHora'] = pd.to_datetime(graficar['FechaHora'], errors='coerce')\n",
    "\n",
    "# Filtrar filas con fechas no válidas\n",
    "graficar = graficar.dropna(subset=['FechaHora'])\n",
    "\n",
    "# Agrupar por día y contar archivos\n",
    "agruparD = graficar['FechaHora'].dt.floor('D').value_counts().sort_index()\n",
    "\n",
    "# Verificar si hay datos para graficar\n",
    "if agruparD.empty:\n",
    "    print(\"⚠️ No hay datos disponibles para graficar.\")\n",
    "else:\n",
    "    # Crear figura\n",
    "    plt.figure(figsize=(10, 5))  # Tamaño más amplio\n",
    "\n",
    "    # Graficar como barra\n",
    "    agruparD.plot(kind='bar', color='royalblue')\n",
    "\n",
    "    # Configuración de etiquetas\n",
    "    plt.title('Archivos recibidos por Día')\n",
    "    plt.xlabel('Día')\n",
    "    plt.ylabel('Cantidad de Archivos')\n",
    "\n",
    "    # Rotar etiquetas del eje X\n",
    "    plt.xticks(rotation=65, ha='right')\n",
    "\n",
    "    # Mostrar gráfico\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del Formato\n",
    "\n",
    "%m: Representa el mes como un número con dos dígitos (01 a 12).\n",
    "\n",
    "%d: Representa el día del mes como un número con dos dígitos (01 a 31).\n",
    "\n",
    "%Y: Representa el año con cuatro dígitos.\n",
    "\n",
    "%I: Representa la hora en formato de 12 horas (01 a 12).\n",
    "\n",
    "%M: Representa los minutos.\n",
    "\n",
    "%p: Representa AM o PM.\n",
    "\n",
    "En nuestro caso como la fecha tiene los Dias y los Meses sin PADD hay que utilizar la siguiente opción\n",
    "\n",
    "### pd.to_datetime(salida['FechaHora'], dayfirst=False).dt.strftime('%m/%d/%Y %I:%M %p')\n",
    "\n",
    "\n",
    "https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/1.0.1/reference/api/pandas.to_datetime.html\n",
    "\n",
    "https://github.com/pandas-dev/pandas/issues/3341\n",
    "\n",
    "In Linux \"#\" is replaced by \"-\":\n",
    "%-d, %-H, %-I, %-j, %-m, %-M, %-S, %-U, %-w, %-W, %-y, %-Y\n",
    "In Windows \"-\" is replaced by \"#\":\n",
    "%#d, %#H, %#I, %#j, %#m, %#M, %#S, %#U, %#w, %#W, %#y, %#Y\n",
    "\n",
    "#Linux\n",
    "mydatetime.strftime('%-m/%d/%Y %-I:%M%p')\n",
    "#Windows\n",
    "mydatetime.strftime('%#m/%d/%Y %#I:%M%p')\n",
    "Source: https://msdn.microsoft.com/en-us/library/fe06s4ak.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar un registro JSON\n",
    "\n",
    "* https://brightdata.es/blog/procedimientos/parse-json-data-with-python\n",
    "* https://docs.python.org/3/tutorial/datastructures.html#dictionaries\n",
    "* https://docs.python.org/3/tutorial/datastructures.html#more-on-lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busco un registro para probar\n",
    "\n",
    "reg=2\n",
    "url = entrada.iloc[reg]['URL']\n",
    "\n",
    "print(url)\n",
    "print('Archivo : ',entrada.iloc[reg]['NombreArchivo'])\n",
    "print('Embarque: ',entrada.iloc[reg]['Embarque'])\n",
    "print('Fecha   : ',entrada.iloc[reg]['FechaHora'])\n",
    "print('Tamaño  : ',entrada.iloc[reg]['Tamaño'])\n",
    "embarque = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Uso\n",
    "\n",
    "https://stackoverflow.com/questions/74118717/create-new-dataframe-with-json-objects-from-another-dataframe#:~:text=Solution%20using%20pandas&text=It%20provides%20a%20DataFrame%20object,dataframe%20with%20the%20original%20one\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar El archivo SALIDA identificando los JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS para la CONSULTA.\n",
    "\n",
    "#### Comienza el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer valores únicos de la columna 'Embarque' para usar en Query SI QUIERO PROCESAR TODO\n",
    "embarques = entrada['Embarque'].unique()\n",
    "\n",
    "# Formatear los valores entre apóstrofes y separados por comas\n",
    "#REGISTROS = ', '.join(f\"'{embarque}'\" for embarque in embarques)\n",
    "\n",
    "REGISTROS = ','.join(f\"{embarque}\" for embarque in embarques)\n",
    "\n",
    "REGISTROS = tuple(REGISTROS.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(REGISTROS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(REGISTROS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETROS SI QUIERO CONSULTAS REGISTROS RECIBIDOSA EN EL ENVÍO --> SOBRE ESCRIBIR REGISTROS\n",
    "\n",
    "REGISTROS=('834879704',\n",
    "'834879927',\n",
    "'834879946',\n",
    "'834879970',\n",
    "'834880047',\n",
    "'834880418',\n",
    "'834880455',\n",
    "'834880469'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES PARA LEER ARCHIVOS JSON\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def procesar_entregas_desde_url(url, modo='imprimir'):\n",
    "    # Descargar el contenido del archivo JSON desde la URL\n",
    "    respuesta = requests.get(url)\n",
    "    respuesta.raise_for_status()  # Esto lanzará una excepción si ocurre un error\n",
    "\n",
    "    # Leer el contenido JSON\n",
    "    datos = respuesta.json()    \n",
    "    resultados = []\n",
    "    \n",
    "    # Leer Datos de la Cabecera    \n",
    "    resultado = f\"\\nOrigen: {datos['LogisticGroupCode']},  Embarque: {datos['Id']}, Date: {datos['Date']}, Carrier: {datos['CarrierName']}\\n\"\n",
    "    resultados.append(resultado)\n",
    "    # Imprimir la información si el modo es 'imprimir'\n",
    "    if modo == 'imprimir':\n",
    "        print(resultado)\n",
    "\n",
    "    # Procesar y almacenar la información en una lista\n",
    "    for stop in datos['StopList']:\n",
    "        # Verificar que la parada tenga entregas\n",
    "        if stop['OperationType'] == 'Dropped' and stop.get('Deliveries'):\n",
    "            for delivery in stop['Deliveries']:\n",
    "                delivery_number = delivery['DeliveryNumber']\n",
    "                location = stop['LocationName']\n",
    "                for item in delivery['Items']:\n",
    "                    material_name = item['MaterialName']\n",
    "                    batch = item.get('Batch', 'N/A')\n",
    "                    qty = item['Qty']\n",
    "                    \n",
    "                    resultado = f\"   DeliveryNumber: {delivery_number}, LocationName: {location}, MaterialName: {material_name}, Batch: {batch}, Qty: {qty}\"\n",
    "                    resultados.append(resultado)\n",
    "\n",
    "                    # Imprimir la información si el modo es 'imprimir'\n",
    "                    if modo == 'imprimir':\n",
    "                        print(resultado)\n",
    "    \n",
    "    # Devolver los resultados si el modo es 'devolver'\n",
    "    if modo == 'devolver':\n",
    "        return resultados\n",
    "\n",
    "    # Almacenar los resultados en un archivo si el modo es 'almacenar'\n",
    "    if modo == 'almacenar':\n",
    "        with open('resultados.txt', 'a', encoding=\"utf-8\") as archivo_salida:\n",
    "            for resultado in resultados:\n",
    "                archivo_salida.write(resultado + '\\n')\n",
    "            archivo_salida.close()\n",
    "                \n",
    "\n",
    "\n",
    "# Ejemplo para validar el uso de la función\n",
    "# url = 'http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638508724764465417-834195574.log'\n",
    "# procesar_entregas_desde_url(url, modo='imprimir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación\n",
    "* Leer el archivo JSON: Utilizamos json.load() para cargar el contenido del archivo JSON en una variable datos.\n",
    "* Procesar las entregas: Iteramos sobre la lista de paradas (StopList). Para cada parada, obtenemos la lista de entregas (Deliveries).\n",
    "* Extraer y mostrar la información: Para cada entrega, extraemos DeliveryNumber, LocationName, MaterialName, Batch, y Qty, y luego imprimimos esta información en el formato deseado.\n",
    "* Función versátil: La función procesar_entregas permite imprimir, devolver o almacenar la información según el modo especificado.\n",
    "\n",
    "##### Ejemplo de uso de la función\n",
    "procesar_entregas('archivo.json', modo='imprimir')\n",
    "\n",
    "Utiliza los PARAMETROS ingresados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRADO y ORDENADO del dataframe para procesar secuencialmente\n",
    "\n",
    "resumen = entrada.loc[entrada[\"Embarque\"].isin(REGISTROS)]\n",
    "salida = resumen.sort_values(by=['Embarque', 'FechaHora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuento de la Cantidad de Archvios por Minuto\n",
    "grouped = salida['FechaHora'].dt.floor('min').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creación del gráfico\n",
    "plt.figure(figsize=(8, 3)) # Aumenta el ancho aquí\n",
    "grouped.plot(kind='bar') \n",
    "plt.title('Files received per minute') \n",
    "plt.xlabel('Minutos') \n",
    "plt.ylabel('Cantidad de Archivos')\n",
    "plt.xticks(rotation=65, ha='right')  #Rotar el ángulo de las etiquetas x\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reenvios = salida['Embarque'].value_counts()\n",
    "\n",
    "# Creación del gráfico\n",
    "plt.figure(figsize=(8, 3)) # Aumenta el ancho aquí\n",
    "reenvios.plot(kind='bar', width=0.5) # Ajuste la anchura de las barras aquí\n",
    "plt.title('Reenvios del Mismo Embarque')\n",
    "plt.xlabel('Embarque')\n",
    "plt.ylabel('Cantidad de Veces')\n",
    "plt.xticks(rotation=65, ha='right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reenvios = salida['Embarque'].value_counts()\n",
    "\n",
    "# Creación del gráfico\n",
    "plt.figure(figsize=(8, 3))  # Ajusta el tamaño del gráfico\n",
    "reenvios.plot(kind='bar', width=0.5, color='skyblue')  # Color opcional\n",
    "\n",
    "# Agregar título y etiquetas\n",
    "plt.title('Reenvíos del Mismo Embarque')\n",
    "plt.xlabel('Embarque')\n",
    "plt.ylabel('Cantidad de Veces')\n",
    "plt.xticks(rotation=65, ha='right')\n",
    "\n",
    "# Calcular el total de embarques\n",
    "total_embarques = reenvios.sum()\n",
    "\n",
    "# Posicionar el label flotante en el centro del gráfico\n",
    "plt.text(\n",
    "    len(reenvios) / 2,  # Posición horizontal en el centro\n",
    "    reenvios.max() / 2,  # Posición vertical en el centro de las barras\n",
    "    f'Total: {total_embarques}', \n",
    "    fontsize=10, color='black', fontweight='bold',\n",
    "    ha='center', va='center', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5')\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUTINA PARA IMPRIMIR SALIDAS por la Terminal\n",
    "\n",
    "for i in range(len(salida)):\n",
    "    if salida.iloc[i]['Embarque'] in (REGISTROS):\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('Embarque: ',salida.iloc[i]['Embarque'])\n",
    "        url = salida.iloc[i]['URL']\n",
    "        print(f'Archivo: ',salida.iloc[i]['FechaHora'],url)\n",
    "        # Procesar cada Embarque\n",
    "        resultado = procesar_entregas_desde_url(url, modo='imprimir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANÁLISIS SOLO DE LOS FALTANTES o INCOMPLETOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETROS SI QUIERO CONSULTAS REGISTROS RECIBIDOSA EN EL ENVÍO --> SOBRE ESCRIBIR REGISTROS\n",
    "\n",
    "FALTANTES=('834879704',\n",
    "'834879927',\n",
    "'834879946',\n",
    "'834879970',\n",
    "'834880047',\n",
    "'834880418',\n",
    "'834880455',\n",
    "'834880469'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRADO y ORDENADO del dataframe para procesar secuencialmente\n",
    "\n",
    "faltan = entrada.loc[entrada[\"Embarque\"].isin(FALTANTES)]\n",
    "fallaron = faltan.sort_values(by=['Embarque', 'FechaHora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuento de la Cantidad de Archvios por Minuto\n",
    "grouped = fallaron['FechaHora'].dt.floor('min').value_counts()\n",
    "\n",
    "reenvios = fallaron['Embarque'].value_counts()\n",
    "\n",
    "# Creación del gráfico\n",
    "plt.figure(figsize=(4, 3)) # Aumenta el ancho aquí\n",
    "reenvios.plot(kind='bar', width=0.5) # Ajuste la anchura de las barras aquí\n",
    "plt.title('Reenvios de Archivos con Embarque Incompletos')\n",
    "plt.xlabel('Embarque')\n",
    "plt.ylabel('Cantidad de Veces')\n",
    "plt.xticks(rotation=65, ha='right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETALLE de los ARCHIVOS JSON con FALTANTES\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# RUTINA PARA IMPRIMIR SALIDAS por la Terminal\n",
    "\n",
    "for i in range(len(salida)):\n",
    "    if salida.iloc[i]['Embarque'] in (FALTANTES):\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('Embarque: ',salida.iloc[i]['Embarque'])\n",
    "        url = salida.iloc[i]['URL']\n",
    "        print(f'Archivo: ',salida.iloc[i]['FechaHora'],url)\n",
    "        # Procesar cada Embarque\n",
    "        resultado = procesar_entregas_desde_url(url, modo='imprimir')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUTINA PARA GRABAR en Archivo las SALIDAS \n",
    "\n",
    "with open('./data/resultados.txt', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(f\"PROCESO DE INTEFACES desde resultado {fecha_inicio}\" + '\\n')\n",
    "    f.close()\n",
    "\n",
    "for i in range(len(salida)):\n",
    "    if salida.iloc[i]['Embarque'] in (FALTANTES):\n",
    "        with open('resultados.txt', 'a', encoding=\"utf-8\") as f:\n",
    "            f.write('\\n----------------------------------------------------------------\\n')\n",
    "            f.write(f\"Embarque: '{salida.iloc[i]['Embarque']}\")\n",
    "            url = salida.iloc[i]['URL']\n",
    "            f.write(f\"Archivo:  {salida.iloc[i]['FechaHora']} - {url}\")\n",
    "            f.close()\n",
    "        # Procesar cada Embarque\n",
    "        resultado = procesar_entregas_desde_url(url, modo='almacenar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras Alternativas para Analizar JSON Complejos\n",
    "\n",
    "https://www.ionos.es/digitalguide/paginas-web/desarrollo-web/python-jsonpath/#:~:text=Para%20que%20Python%20pueda%20leer,%E2%80%9D%20o%20%E2%80%9Cload()%E2%80%9D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTAR los datos a EXCEL \n",
    "salida.to_excel(\"./salida.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Generar Conexión con SQL SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONECTAR con SERVIDOR SQL SERVER\n",
    "\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "secrets = dotenv_values(\".env\")\n",
    "local_secrets = dotenv_values(\".env.dev\")\n",
    "\n",
    "SERVER = secrets[\"SERVIDOR\"]\n",
    "DATABASE = secrets[\"DATABASE\"]\n",
    "USERNAME = secrets[\"USUARIO\"]\n",
    "PASSWORD = secrets[\"CONTRASENA\"]\n",
    "PORT = secrets[\"PUERTO\"]\n",
    "DRIVER = secrets[\"DRIVER\"]\n",
    "OPTIONS= secrets[\"OPTION\"]\n",
    "\n",
    "connectionString = f'DRIVER={DRIVER};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD};{OPTIONS}'\n",
    "print(connectionString)\n",
    "conn = pyodbc.connect(connectionString) \n",
    "\n",
    "#    DRIVER={ODBC Driver 18 for SQL Server};SERVER=213.134.40.73,9595;DATABASE=seamtrack;UID=eduardo.ettlin@vigiloo.com.ar;PWD=Aladelta10$;encrypt=no\n",
    "#    DRIVER={ODBC Driver 18 for SQL Server};SERVER=username;DATABASE=secret;UID=eduar;PWD=Aladelta10$;encrypt=no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Extraerlos Datos procesados que están en SQL SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armar la Consulta con sus PARAMETROS\n",
    "\n",
    "SQL_QUERY = f\"\"\"\n",
    "SELECT   DISTINCT     \n",
    "A.[RefId] as EMBARQUE\n",
    ",D.RefId as DELIVERY\n",
    ",A.[Date] as FECHA\n",
    ",D.[PurchaseOrderIdRef] as PEDIDO\n",
    ",D.[DestinationCode]\n",
    ",D.[DestinationName]\n",
    ",E.[MaterialCode]\n",
    ",E.[MaterialName]\n",
    ",E.[Batch]\n",
    ",STR(E.[Qty],6) as QTY\n",
    ",A.[LogisticGroupId]\n",
    "\n",
    "FROM [seamtrack].[vigiloo].[Shipment] A\n",
    "LEFT JOIN [seamtrack].[vigiloo].[ShipmentDestination] B\n",
    "ON B.[ShipmentId] = A.Id\n",
    "LEFT JOIN [seamtrack].[vigiloo].[Delivery] D\n",
    "ON D.[ShipmentId] = A.Id\n",
    "LEFT JOIN [seamtrack].[vigiloo].[DeliveryItem] E\n",
    "ON E.[DeliveryId] = D.Id\n",
    "    \n",
    "WHERE A.[RefId] IN {REGISTROS}\n",
    "ORDER BY A.RefId,D.RefId, D.[DestinationCode],E.[MaterialCode];\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SQL_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la Consulta\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(SQL_QUERY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPRIMIR Resultados de la Consulta\n",
    "for r in records:\n",
    "    print(f\"{r.EMBARQUE}\\t{r.DELIVERY}\\t{r.FECHA}\\t{r.DestinationCode}\\t{r.DestinationName}\\t{r.MaterialName}\\t{r.Batch}\\t{r.QTY}\\t{r.LogisticGroupId}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar DATAFRAME con los resultados de las consultas\n",
    "df = pd.DataFrame((tuple(t) for t in records)) \n",
    "df.columns = ['EMBARQUE','DELIVERY','FECHA','PEDIDO','DestinationCode','DestinationName','MaterialCode','MaterialName','Batch','QTY','LogisticGroupId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar Registros con datos Nulos\n",
    "df.dropna(subset=['EMBARQUE','DELIVERY'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adecuar el Grupo Logístico\n",
    "df[\"LogisticGroupId\"] = df[\"LogisticGroupId\"].replace(\n",
    "    { \"75247427-34FD-41A3-B7E0-F0B8312EADA8\": \"Monsanto\", \"F21EE1F9-4823-42B4-AD40-8C81F2847818\": \"BAYER\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTAR DATOS EN FORMATO EXCEL\n",
    "\n",
    "df.to_excel(\"./data/SQLServer.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTROL COMPLETO de TODAS LAS INTERFACES\n",
    "\n",
    "#### Verificar si todo lo que está en LoadUpload EXISTE en las bases de VIGILOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(REGISTROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armar la Consulta con sus PARAMETROS\n",
    "\n",
    "SQL_QUERY = f\"\"\"\n",
    "SELECT DISTINCT     \n",
    "       A.[RefId] as EMBARQUE\n",
    "FROM [seamtrack].[vigiloo].[Shipment] A\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la Consulta\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(SQL_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar DATAFRAME con los resultados de las consultas\n",
    "sqldf = pd.DataFrame((tuple(t) for t in records)) \n",
    "sqldf.columns = ['EMBARQUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de DATAFRAMES\n",
    "\n",
    "#### 1) Archivos en Interfaces que NO ESTAN en la base de Datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIZANDO LEFT JOIN\n",
    "# Realizar un merge left con un indicador que muestre de dónde vienen los datos\n",
    "merged_df = pd.merge(df, sqldf, on='EMBARQUE', how='left', indicator=True)\n",
    "\n",
    "# Filtrar los registros que solo existen en el DataFrame 'df'\n",
    "result_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Seleccionar solo las columnas del DataFrame original 'df'\n",
    "result_df = result_df[df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de INTEFACES NO PROCESADAS: \",len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una serie booleana que indica si cada valor de 'EMBARQUE' en 'df' está también en 'sqldf'\n",
    "mask = df['EMBARQUE'].isin(sqldf['EMBARQUE'])\n",
    "\n",
    "# Usar la negación de la máscara para filtrar registros\n",
    "result_df = df[~mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2) Embarque que estan en la Base de Datos y NO ESTAN en Interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIZANDO JOIN RIGHT\n",
    "# Realizar un merge right con un indicador que muestre de dónde vienen los datos\n",
    "merged_df = pd.merge(df, sqldf, on='EMBARQUE', how='right', indicator=True)\n",
    "\n",
    "# Filtrar los registros que solo existen en el DataFrame 'sqldf'\n",
    "result_df = merged_df[merged_df['_merge'] == 'right_only']\n",
    "\n",
    "# Seleccionar solo las columnas del DataFrame original 'sqldf'\n",
    "result_df = result_df[sqldf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVA --> Verificando si está contenido\n",
    "# Crear una serie booleana que indica si cada valor de 'EMBARQUE' en 'sqldf' está también en 'df'\n",
    "mask = sqldf['EMBARQUE'].isin(df['EMBARQUE'])\n",
    "\n",
    "# Usar la negación de la máscara para filtrar registros\n",
    "result_df = sqldf[~mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de EMBARQUE en la BD que no estan en INTEFACES: \",len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
