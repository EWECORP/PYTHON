{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def obtener_enlaces(url):\n",
    "    # Realizar la petición HTTP a la página web\n",
    "    respuesta = requests.get(url)\n",
    "    # Si la petición fue exitosa, procesar el contenido\n",
    "    if respuesta.status_code == 200:\n",
    "        soup = BeautifulSoup(respuesta.content, 'html.parser')\n",
    "        # Extraer todos los elementos <a> de la página\n",
    "        enlaces = soup.find_all('a', href=True)\n",
    "        # Crear una lista para almacenar los datos\n",
    "        datos = []\n",
    "        # Recorrer cada enlace y almacenar la información necesaria\n",
    "        for enlace in enlaces:\n",
    "            # Extraer el href del enlace\n",
    "            href = enlace['href']\n",
    "            # Extraer el texto del enlace, que es el nombre del archivo\n",
    "            texto = enlace.text\n",
    "            # Intentar extraer las observaciones que están en el contenido antes del enlace\n",
    "            # Esto asume que el texto de observaciones está justo antes del enlace\n",
    "            observaciones = enlace.previous_sibling\n",
    "            if observaciones:\n",
    "                observaciones = observaciones.strip()  #Remueve los espacios al principio y al final de la línea\n",
    "                # Dividir las observaciones en partes\n",
    "                partes = observaciones.split(\"   \")\n",
    "                #print(partes)\n",
    "                # Extraer la fecha y la hora (primeras dos partes)\n",
    "                fecha_hora = ' '.join(partes[:1])\n",
    "                #print(fecha_hora)\n",
    "                # Extraer el tamaño (última parte)\n",
    "                tamaño = partes[-1]\n",
    "                #print(tamaño)\n",
    "            else:\n",
    "                fecha_hora = \"No disponible\"\n",
    "                tamaño = \"No disponible\"\n",
    "            # Añadir a la lista como una tupla\n",
    "            datos.append((texto, \"http://rtv-b2b-api-logs.vigiloo.net\" + href, fecha_hora, tamaño))    # datos.append((texto, url + href, fecha_hora, tamaño))\n",
    "        # Convertir la lista en un DataFrame\n",
    "        df = pd.DataFrame(datos, columns=['NombreArchivo', 'URL', 'FechaHora', 'Tamaño'])\n",
    "        df.drop(0,axis=0)\n",
    "        # Convertir la columna 'FechaHora' a tipo datetime\n",
    "        df['FechaHora'] = pd.to_datetime(df['FechaHora'], dayfirst=False, format='%m/%d/%Y %I:%M %p',errors='coerce') \n",
    "        # Convertir la columna 'Tamaño' a tipo numérico\n",
    "        df['Tamaño'] = pd.to_numeric(df['Tamaño'], errors='coerce')\n",
    "        df['Embarque'] = df['NombreArchivo'].str.extract(r'-(\\d+)\\.log')\n",
    "        df.drop(0,axis=0, inplace=True)  # Borro la Primera línea que apunta al directorio padre        \n",
    "        return df\n",
    "    else:\n",
    "        return \"Error al acceder a la página\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            NombreArchivo                                                URL  \\\n",
      "1  638270843928515554.log  http://rtv-b2b-api-logs.vigiloo.net/LoadUpload...   \n",
      "\n",
      "            FechaHora  Tamaño Embarque  \n",
      "1 2023-08-08 08:39:00  2404.0      NaN  \n"
     ]
    }
   ],
   "source": [
    "# URL de la página de donde se desean extraer los enlaces\n",
    "url = \"http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/\"\n",
    "archivos_df = obtener_enlaces(url)\n",
    "if isinstance(archivos_df, pd.DataFrame):\n",
    "   print(archivos_df.head(1))\n",
    "else:\n",
    "   print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'FechaHora' a tipo datetime\n",
    "\n",
    "import datetime\n",
    "\n",
    "#salida['FechaHora'] = pd.to_datetime(salida['FechaHora'], dayfirst=False, format='%m/%d/%Y %I:%M %p') \n",
    "#salida['FechaHora'] = pd.to_datetime(salida['FechaHora'], format='%m/%d/%Y %I:%M %p')  # 10/16/2023  1:23 PM\n",
    "\n",
    "#salida['FechaHora'] = pd.to_datetime(salida['FechaHora'], dayfirst=False).dt.strftime('%m/%d/%Y %I:%M %p')\n",
    "archivos_df['FechaHora'] = pd.to_datetime(archivos_df['FechaHora'], dayfirst=False, format='%m/%d/%Y %I:%M %p',errors='coerce')   # Convierte en Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime(year=2024,month=5,day=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomas las últimas 50 fílas válidas\n",
    "# salida= archivos_df.tail(51)\n",
    "# salida.drop(salida.index[-1], axis=0, inplace = True) # Elimina la última fila\n",
    "\n",
    "\n",
    "salida = archivos_df[(archivos_df['FechaHora'] >=datetime.datetime(year=2024,month=5,day=1))]\n",
    "# print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del Formato\n",
    "\n",
    "%m: Representa el mes como un número con dos dígitos (01 a 12).\n",
    "\n",
    "%d: Representa el día del mes como un número con dos dígitos (01 a 31).\n",
    "\n",
    "%Y: Representa el año con cuatro dígitos.\n",
    "\n",
    "%I: Representa la hora en formato de 12 horas (01 a 12).\n",
    "\n",
    "%M: Representa los minutos.\n",
    "\n",
    "%p: Representa AM o PM.\n",
    "\n",
    "En nuestro caso como la fecha tiene los Dias y los Meses sin PADD hay que utilizar la siguiente opción\n",
    "\n",
    "### pd.to_datetime(salida['FechaHora'], dayfirst=False).dt.strftime('%m/%d/%Y %I:%M %p')\n",
    "\n",
    "\n",
    "https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/1.0.1/reference/api/pandas.to_datetime.html\n",
    "\n",
    "https://github.com/pandas-dev/pandas/issues/3341\n",
    "\n",
    "In Linux \"#\" is replaced by \"-\":\n",
    "%-d, %-H, %-I, %-j, %-m, %-M, %-S, %-U, %-w, %-W, %-y, %-Y\n",
    "In Windows \"-\" is replaced by \"#\":\n",
    "%#d, %#H, %#I, %#j, %#m, %#M, %#S, %#U, %#w, %#W, %#y, %#Y\n",
    "\n",
    "#Linux\n",
    "mydatetime.strftime('%-m/%d/%Y %-I:%M%p')\n",
    "#Windows\n",
    "mydatetime.strftime('%#m/%d/%Y %#I:%M%p')\n",
    "Source: https://msdn.microsoft.com/en-us/library/fe06s4ak.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NombreArchivo                     638511256466635778-834265169.log\n",
       "URL              http://rtv-b2b-api-logs.vigiloo.net/LoadUpload...\n",
       "FechaHora                                      2024-05-12 14:47:00\n",
       "Tamaño                                                      1036.0\n",
       "Embarque                                                 834265169\n",
       "Name: 3661, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida.loc[salida.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 46 entries, 3634 to 3679\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   NombreArchivo  46 non-null     object        \n",
      " 1   URL            46 non-null     object        \n",
      " 2   FechaHora      46 non-null     datetime64[ns]\n",
      " 3   Tamaño         46 non-null     float64       \n",
      " 4   Embarque       46 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "salida.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar un archivo JSON\n",
    "\n",
    "* https://brightdata.es/blog/procedimientos/parse-json-data-with-python\n",
    "* https://docs.python.org/3/tutorial/datastructures.html#dictionaries\n",
    "* https://docs.python.org/3/tutorial/datastructures.html#more-on-lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638510162553663120-834264837.log\n",
      "Archivo :  638510162553663120-834264837.log\n",
      "Embarque:  834264837\n",
      "Fecha   :  2024-05-11 08:24:00\n",
      "Tamaño  :  907.0\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "# Biscp un registro para probar\n",
    "\n",
    "reg=2\n",
    "url = salida.iloc[reg]['URL']\n",
    "\n",
    "print(url)\n",
    "print('Archivo : ',salida.iloc[reg]['NombreArchivo'])\n",
    "print('Embarque: ',salida.iloc[reg]['Embarque'])\n",
    "print('Fecha   : ',salida.iloc[reg]['FechaHora'])\n",
    "print('Tamaño  : ',salida.iloc[reg]['Tamaño'])\n",
    "embarque = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Uso\n",
    "\n",
    "https://stackoverflow.com/questions/74118717/create-new-dataframe-with-json-objects-from-another-dataframe#:~:text=Solution%20using%20pandas&text=It%20provides%20a%20DataFrame%20object,dataframe%20with%20the%20original%20one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPANDIR Embarque con el contenido de los registros de 2do nivel\n",
    "\n",
    "# Defino la function que hace un parse al JSON string y retorna un dictionary\n",
    "def parse_json(x):\n",
    "  try:\n",
    "    return json.dumps(x)\n",
    "  except:\n",
    "    return 'Error'\n",
    "\n",
    "#Apply the function to the JSON column and store the result in a new column\n",
    "embarque['json_dict'] = embarque['StopList'].apply(parse_json)\n",
    "\n",
    "# Use the pandas.json_normalize function to convert the dictionary column into a new dataframe\n",
    "df_json = pd.json_normalize(embarque['StopList'])\n",
    "\n",
    "# Drop the original JSON column and merge the new dataframe\n",
    "df = embarque.drop('StopList', axis=1)\n",
    "embarque = pd.concat([embarque, df_json], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Id                 2 non-null      int64 \n",
      " 1   Date               2 non-null      object\n",
      " 2   LogisticGroupCode  2 non-null      object\n",
      " 3   CarrierCode        2 non-null      int64 \n",
      " 4   CarrierName        2 non-null      object\n",
      " 5   StopList           2 non-null      object\n",
      " 6   json_dict          2 non-null      object\n",
      " 7   StopNumber         2 non-null      int64 \n",
      " 8   OperationType      2 non-null      object\n",
      " 9   DroppedNumber      2 non-null      int64 \n",
      " 10  PickedNumber       2 non-null      int64 \n",
      " 11  LocationCode       2 non-null      object\n",
      " 12  LocationName       2 non-null      object\n",
      " 13  LocationLatitude   0 non-null      object\n",
      " 14  LocationLongitude  0 non-null      object\n",
      " 15  Deliveries         1 non-null      object\n",
      "dtypes: int64(5), object(11)\n",
      "memory usage: 388.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "embarque.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embarque['json_dict'] = embarque['Deliveries'].apply(parse_json)\n",
    "\n",
    "#df['json_dict'] = df['Deliveries'].apply(parse_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de datos (asegúrate de tener tus datos reales cargados)\n",
    "# data = {...}\n",
    "# df_deliveries = pd.DataFrame(data)\n",
    "\n",
    "def process_deliveries(row):\n",
    "    if row['DroppedNumber'] > 0 and pd.notna(row['Deliveries']):\n",
    "        location = row['LocationName']\n",
    "        # Convertir el contenido de la columna 'Deliveries' desde JSON a objeto Python si aún no está hecho\n",
    "        if isinstance(row['Deliveries'], str):\n",
    "            deliveries = eval(row['Deliveries'])\n",
    "        else:\n",
    "            deliveries = row['Deliveries']\n",
    "        \n",
    "        # Recorrer cada entrega en 'Deliveries'\n",
    "        for delivery in deliveries:\n",
    "            delivery_number = delivery['DeliveryNumber']            \n",
    "            # Recorrer cada ítem en 'Items' de cada entrega\n",
    "            for item in delivery['Items']:\n",
    "                material_name = item['MaterialName']\n",
    "                batch = item['Batch']\n",
    "                qty = item['Qty']\n",
    "                # Podemos elegir imprimir, almacenar o devolver esta información\n",
    "                print(f\" DeliveryNumber: {delivery_number}, LocationName: {location}, MaterialName: {material_name}, Batch: {batch}, Qty: {qty}\")\n",
    "\n",
    "# Aplicar la función a cada fila del DataFrame\n",
    "#df.apply(process_deliveries, axis=1)\n",
    "embarque.apply(process_deliveries, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Embarque:  834261368\n",
      "Archivo:  2024-05-09 15:57:00 http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638508706321030403-834261368.log\n",
      "Origen:  SAPP08  - Date:  0001-01-01T00:00:00  - Carrier:  ZARCAM S A\n",
      " DeliveryNumber: 5011484115, LocationName: COMPAÑIA DE INSUMOS Y GRANOS S A, MaterialName: LA TIJERETA PLATINUM II,MON301512,48X20L, Batch: None, Qty: 19200.0\n",
      "----------------------------------------------------------------\n",
      "Embarque:  834261373\n",
      "Archivo:  2024-05-09 15:57:00 http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638508706321030403-834261373.log\n",
      "Origen:  SAPP08  - Date:  0001-01-01T00:00:00  - Carrier:  ZARCAM S A\n",
      " DeliveryNumber: 5011478200, LocationName: AGRO LEBEN SRL, MaterialName: RUP CONTROLMAX,AR,64x15KG BOX, Batch: None, Qty: 1905.0\n",
      " DeliveryNumber: 5011478200, LocationName: AGRO LEBEN SRL, MaterialName: HARNESS,AR,48x20L BT MON58415, Batch: None, Qty: 740.0\n",
      " DeliveryNumber: 5011478200, LocationName: AGRO LEBEN SRL, MaterialName: RUP TOP,AR,48x20L BT MON301515, Batch: None, Qty: 2580.0\n",
      " DeliveryNumber: 5011478200, LocationName: AGRO LEBEN SRL, MaterialName: RUP CONTROLMAX,AR,64x15KG BOX, Batch: None, Qty: 5475.0\n",
      " DeliveryNumber: 5011478200, LocationName: AGRO LEBEN SRL, MaterialName: RUP CONTROLMAX,AR,64x15KG BOX, Batch: None, Qty: 1980.0\n",
      " DeliveryNumber: 5011478200, LocationName: AGRO LEBEN SRL, MaterialName: RUP TOP,AR,48x20L BT MON301515, Batch: None, Qty: 7000.0\n",
      "----------------------------------------------------------------\n",
      "Embarque:  834261712\n",
      "Archivo:  2024-05-09 17:33:00 http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638508764034934058-834261712.log\n",
      "Origen:  SAPP4S  - Date:  2024-05-10 16:37:00+00:00  - Carrier:  ZARCAM S.A.\n",
      " DeliveryNumber: 8480743658, LocationName: ADECO AGROPECUARIA S.A., MaterialName: PUCARA FS400 12X1L BOT AR, Batch: None, Qty: 400.0\n",
      "----------------------------------------------------------------\n",
      "Embarque:  834261712\n",
      "Archivo:  2024-05-10 08:58:00 http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638509318975877083-834261712.log\n",
      "Origen:  SAPP4S  - Date:  2024-05-10 16:37:00+00:00  - Carrier:  ZARCAM S.A.\n",
      "----------------------------------------------------------------\n",
      "Embarque:  834261368\n",
      "Archivo:  2024-05-13 11:35:00 http://rtv-b2b-api-logs.vigiloo.net/LoadUpload/638512005025663175-834261368.log\n",
      "Origen:  SAPP08  - Date:  0001-01-01T00:00:00  - Carrier:  ZARCAM S A\n",
      " DeliveryNumber: 5011484115, LocationName: COMPAÑIA DE INSUMOS Y GRANOS S A, MaterialName: LA TIJERETA PLATINUM II,MON301512,48X20L, Batch: None, Qty: 19200.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(salida)):\n",
    "    if salida.iloc[i]['Embarque'] in ('834261368', '834261373', '834261712'):\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('Embarque: ',salida.iloc[i]['Embarque'])\n",
    "        url = salida.iloc[i]['URL']\n",
    "        print('Archivo: ',salida.iloc[i]['FechaHora'],url)\n",
    "        # Procesar cada Embarque\n",
    "        embarque = pd.read_json(url)\n",
    "        embarque['json_dict'] = embarque['StopList'].apply(parse_json)\n",
    "        df_json = pd.json_normalize(embarque['StopList'])\n",
    "        embarque = pd.concat([embarque, df_json], axis=1)\n",
    "        print('Origen: ',embarque.iloc[0]['LogisticGroupCode'],' - Date: ',embarque.iloc[0]['Date'],' - Carrier: ',embarque.iloc[0]['CarrierName'])\n",
    "        embarque.apply(process_deliveries, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar con los Datos que están en SQL SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVER={ODBC Driver 18 for SQL Server};SERVER=213.134.40.73,9595;DATABASE=seamtrack;UID=eduardo.ettlin@vigiloo.com.ar;PWD=Aladelta10$;encrypt=no\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "SERVER = '213.134.40.73,9595'\n",
    "DATABASE = 'seamtrack'\n",
    "USERNAME = 'eduardo.ettlin@vigiloo.com.ar'\n",
    "PASSWORD = 'Aladelta10$'\n",
    "OPTIONS= 'encrypt=no'\n",
    "\n",
    "connectionString = f'DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD};{OPTIONS}'\n",
    "print(connectionString)\n",
    "conn = pyodbc.connect(connectionString) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTROS=\"\"\"\n",
    "'834261368',\n",
    "'834261373',\n",
    "'834261712'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SQL_QUERY = f\"\"\"\n",
    "SELECT   DISTINCT     \n",
    "A.[RefId] as EMBARQUE\n",
    ",D.RefId as DELIVERY\n",
    ",A.[Date] as FECHA\n",
    ",D.[PurchaseOrderIdRef] as PEDIDO\n",
    ",D.[DestinationCode]\n",
    ",D.[DestinationName]\n",
    ",E.[MaterialCode]\n",
    ",E.[MaterialName]\n",
    ",E.[Batch]\n",
    ",STR(E.[Qty],6) as QTY\n",
    ",A.[LogisticGroupId]\n",
    "\n",
    "FROM [seamtrack].[vigiloo].[Shipment] A\n",
    "LEFT JOIN [seamtrack].[vigiloo].[ShipmentDestination] B\n",
    "ON B.[ShipmentId] = A.Id\n",
    "LEFT JOIN [seamtrack].[vigiloo].[Delivery] D\n",
    "ON D.[ShipmentId] = A.Id\n",
    "LEFT JOIN [seamtrack].[vigiloo].[DeliveryItem] E\n",
    "ON E.[DeliveryId] = D.Id\n",
    "    \n",
    "WHERE A.[RefId] IN ( {REGISTROS}) ORDER BY A.RefId,D.RefId, D.[DestinationCode],E.[MaterialCode];\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT   DISTINCT     \n",
      "A.[RefId] as EMBARQUE\n",
      ",D.RefId as DELIVERY\n",
      ",A.[Date] as FECHA\n",
      ",D.[PurchaseOrderIdRef] as PEDIDO\n",
      ",D.[DestinationCode]\n",
      ",D.[DestinationName]\n",
      ",E.[MaterialCode]\n",
      ",E.[MaterialName]\n",
      ",E.[Batch]\n",
      ",STR(E.[Qty],6) as QTY\n",
      ",A.[LogisticGroupId]\n",
      "\n",
      "FROM [seamtrack].[vigiloo].[Shipment] A\n",
      "LEFT JOIN [seamtrack].[vigiloo].[ShipmentDestination] B\n",
      "ON B.[ShipmentId] = A.Id\n",
      "LEFT JOIN [seamtrack].[vigiloo].[Delivery] D\n",
      "ON D.[ShipmentId] = A.Id\n",
      "LEFT JOIN [seamtrack].[vigiloo].[DeliveryItem] E\n",
      "ON E.[DeliveryId] = D.Id\n",
      "    \n",
      "WHERE A.[RefId] IN ( \n",
      "'834261368',\n",
      "'834261373',\n",
      "'834261712'\n",
      ") ORDER BY A.RefId,D.RefId, D.[DestinationCode],E.[MaterialCode];\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SQL_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x1f8fb00ce30>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(SQL_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834261368\t5011484115\t2024-05-10 00:00:00\t0003391247\tCOMPAÑIA DE INSUMOS Y GRANOS S A\tLA TIJERETA PLATINUM II,MON301512,48X20L\tNone\t 19200\t75247427-34FD-41A3-B7E0-F0B8312EADA8\n",
      "834261373\t5011478200\t2024-05-10 00:00:00\t0003107764\tAGRO LEBEN SRL\tHARNESS,AR,48x20L BT MON58415\tNone\t   740\t75247427-34FD-41A3-B7E0-F0B8312EADA8\n",
      "834261373\t5011478200\t2024-05-10 00:00:00\t0003107764\tAGRO LEBEN SRL\tRUP CONTROLMAX,AR,64x15KG BOX\tNone\t  1980\t75247427-34FD-41A3-B7E0-F0B8312EADA8\n",
      "834261373\t5011478200\t2024-05-10 00:00:00\t0003107764\tAGRO LEBEN SRL\tRUP TOP,AR,48x20L BT MON301515\tNone\t  7000\t75247427-34FD-41A3-B7E0-F0B8312EADA8\n",
      "834261712\t8480743658\t2024-05-10 16:37:00\t0004339120\tADECO AGROPECUARIA S.A.\tPUCARA FS400 12X1L BOT AR\tNone\t   400\tF21EE1F9-4823-42B4-AD40-8C81F2847818\n"
     ]
    }
   ],
   "source": [
    "records = cursor.fetchall()\n",
    "for r in records:\n",
    "    print(f\"{r.EMBARQUE}\\t{r.DELIVERY}\\t{r.FECHA}\\t{r.DestinationCode}\\t{r.DestinationName}\\t{r.MaterialName}\\t{r.Batch}\\t{r.QTY}\\t{r.LogisticGroupId}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((tuple(t) for t in records)) \n",
    "df.columns = ['EMBARQUE','DELIVERY','FECHA','PEDIDO','DestinationCode','DestinationName','MaterialCode','MaterialName','Batch','QTY','LogisticGroupId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adecuar el Grupo Logístico\n",
    "df[\"LogisticGroupId\"] = df[\"LogisticGroupId\"].replace(\n",
    "    { \"75247427-34FD-41A3-B7E0-F0B8312EADA8\": \"Monsanto\", \"F21EE1F9-4823-42B4-AD40-8C81F2847818\": \"BAYER\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMBARQUE</th>\n",
       "      <th>DELIVERY</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>PEDIDO</th>\n",
       "      <th>DestinationCode</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>MaterialCode</th>\n",
       "      <th>MaterialName</th>\n",
       "      <th>Batch</th>\n",
       "      <th>QTY</th>\n",
       "      <th>LogisticGroupId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834261368</td>\n",
       "      <td>5011484115</td>\n",
       "      <td>2024-05-10 00:00:00</td>\n",
       "      <td>0829025864</td>\n",
       "      <td>0003391247</td>\n",
       "      <td>COMPAÑIA DE INSUMOS Y GRANOS S A</td>\n",
       "      <td>30202284</td>\n",
       "      <td>LA TIJERETA PLATINUM II,MON301512,48X20L</td>\n",
       "      <td>None</td>\n",
       "      <td>19200</td>\n",
       "      <td>Monsanto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>834261373</td>\n",
       "      <td>5011478200</td>\n",
       "      <td>2024-05-10 00:00:00</td>\n",
       "      <td>0829020942</td>\n",
       "      <td>0003107764</td>\n",
       "      <td>AGRO LEBEN SRL</td>\n",
       "      <td>10434277</td>\n",
       "      <td>HARNESS,AR,48x20L BT MON58415</td>\n",
       "      <td>None</td>\n",
       "      <td>740</td>\n",
       "      <td>Monsanto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>834261373</td>\n",
       "      <td>5011478200</td>\n",
       "      <td>2024-05-10 00:00:00</td>\n",
       "      <td>0829020942</td>\n",
       "      <td>0003107764</td>\n",
       "      <td>AGRO LEBEN SRL</td>\n",
       "      <td>12331311</td>\n",
       "      <td>RUP CONTROLMAX,AR,64x15KG BOX</td>\n",
       "      <td>None</td>\n",
       "      <td>1980</td>\n",
       "      <td>Monsanto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>834261373</td>\n",
       "      <td>5011478200</td>\n",
       "      <td>2024-05-10 00:00:00</td>\n",
       "      <td>0829020942</td>\n",
       "      <td>0003107764</td>\n",
       "      <td>AGRO LEBEN SRL</td>\n",
       "      <td>30146700</td>\n",
       "      <td>RUP TOP,AR,48x20L BT MON301515</td>\n",
       "      <td>None</td>\n",
       "      <td>7000</td>\n",
       "      <td>Monsanto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>834261712</td>\n",
       "      <td>8480743658</td>\n",
       "      <td>2024-05-10 16:37:00</td>\n",
       "      <td>8450206770</td>\n",
       "      <td>0004339120</td>\n",
       "      <td>ADECO AGROPECUARIA S.A.</td>\n",
       "      <td>80897995</td>\n",
       "      <td>PUCARA FS400 12X1L BOT AR</td>\n",
       "      <td>None</td>\n",
       "      <td>400</td>\n",
       "      <td>BAYER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EMBARQUE    DELIVERY               FECHA      PEDIDO DestinationCode  \\\n",
       "0  834261368  5011484115 2024-05-10 00:00:00  0829025864      0003391247   \n",
       "1  834261373  5011478200 2024-05-10 00:00:00  0829020942      0003107764   \n",
       "2  834261373  5011478200 2024-05-10 00:00:00  0829020942      0003107764   \n",
       "3  834261373  5011478200 2024-05-10 00:00:00  0829020942      0003107764   \n",
       "4  834261712  8480743658 2024-05-10 16:37:00  8450206770      0004339120   \n",
       "\n",
       "                    DestinationName MaterialCode  \\\n",
       "0  COMPAÑIA DE INSUMOS Y GRANOS S A     30202284   \n",
       "1                    AGRO LEBEN SRL     10434277   \n",
       "2                    AGRO LEBEN SRL     12331311   \n",
       "3                    AGRO LEBEN SRL     30146700   \n",
       "4           ADECO AGROPECUARIA S.A.     80897995   \n",
       "\n",
       "                               MaterialName Batch     QTY LogisticGroupId  \n",
       "0  LA TIJERETA PLATINUM II,MON301512,48X20L  None   19200        Monsanto  \n",
       "1             HARNESS,AR,48x20L BT MON58415  None     740        Monsanto  \n",
       "2             RUP CONTROLMAX,AR,64x15KG BOX  None    1980        Monsanto  \n",
       "3            RUP TOP,AR,48x20L BT MON301515  None    7000        Monsanto  \n",
       "4                 PUCARA FS400 12X1L BOT AR  None     400           BAYER  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   EMBARQUE         5 non-null      object        \n",
      " 1   DELIVERY         5 non-null      object        \n",
      " 2   FECHA            5 non-null      datetime64[ns]\n",
      " 3   PEDIDO           5 non-null      object        \n",
      " 4   DestinationCode  5 non-null      object        \n",
      " 5   DestinationName  5 non-null      object        \n",
      " 6   MaterialCode     5 non-null      object        \n",
      " 7   MaterialName     5 non-null      object        \n",
      " 8   Batch            0 non-null      object        \n",
      " 9   QTY              5 non-null      object        \n",
      " 10  LogisticGroupId  5 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(10)\n",
      "memory usage: 572.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
